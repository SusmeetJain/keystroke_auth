{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keystroke dynamics based biometric authentication\n",
    "\n",
    "dataset: http://www.cs.cmu.edu/~keystroke/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('DSL-StrongPasswordData.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>sessionIndex</th>\n",
       "      <th>rep</th>\n",
       "      <th>H.period</th>\n",
       "      <th>DD.period.t</th>\n",
       "      <th>UD.period.t</th>\n",
       "      <th>H.t</th>\n",
       "      <th>DD.t.i</th>\n",
       "      <th>UD.t.i</th>\n",
       "      <th>H.i</th>\n",
       "      <th>...</th>\n",
       "      <th>H.a</th>\n",
       "      <th>DD.a.n</th>\n",
       "      <th>UD.a.n</th>\n",
       "      <th>H.n</th>\n",
       "      <th>DD.n.l</th>\n",
       "      <th>UD.n.l</th>\n",
       "      <th>H.l</th>\n",
       "      <th>DD.l.Return</th>\n",
       "      <th>UD.l.Return</th>\n",
       "      <th>H.Return</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>s002</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1491</td>\n",
       "      <td>0.3979</td>\n",
       "      <td>0.2488</td>\n",
       "      <td>0.1069</td>\n",
       "      <td>0.1674</td>\n",
       "      <td>0.0605</td>\n",
       "      <td>0.1169</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1349</td>\n",
       "      <td>0.1484</td>\n",
       "      <td>0.0135</td>\n",
       "      <td>0.0932</td>\n",
       "      <td>0.3515</td>\n",
       "      <td>0.2583</td>\n",
       "      <td>0.1338</td>\n",
       "      <td>0.3509</td>\n",
       "      <td>0.2171</td>\n",
       "      <td>0.0742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>s002</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.1111</td>\n",
       "      <td>0.3451</td>\n",
       "      <td>0.2340</td>\n",
       "      <td>0.0694</td>\n",
       "      <td>0.1283</td>\n",
       "      <td>0.0589</td>\n",
       "      <td>0.0908</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1412</td>\n",
       "      <td>0.2558</td>\n",
       "      <td>0.1146</td>\n",
       "      <td>0.1146</td>\n",
       "      <td>0.2642</td>\n",
       "      <td>0.1496</td>\n",
       "      <td>0.0839</td>\n",
       "      <td>0.2756</td>\n",
       "      <td>0.1917</td>\n",
       "      <td>0.0747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>s002</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.1328</td>\n",
       "      <td>0.2072</td>\n",
       "      <td>0.0744</td>\n",
       "      <td>0.0731</td>\n",
       "      <td>0.1291</td>\n",
       "      <td>0.0560</td>\n",
       "      <td>0.0821</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1621</td>\n",
       "      <td>0.2332</td>\n",
       "      <td>0.0711</td>\n",
       "      <td>0.1172</td>\n",
       "      <td>0.2705</td>\n",
       "      <td>0.1533</td>\n",
       "      <td>0.1085</td>\n",
       "      <td>0.2847</td>\n",
       "      <td>0.1762</td>\n",
       "      <td>0.0945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>s002</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.1291</td>\n",
       "      <td>0.2515</td>\n",
       "      <td>0.1224</td>\n",
       "      <td>0.1059</td>\n",
       "      <td>0.2495</td>\n",
       "      <td>0.1436</td>\n",
       "      <td>0.1040</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1457</td>\n",
       "      <td>0.1629</td>\n",
       "      <td>0.0172</td>\n",
       "      <td>0.0866</td>\n",
       "      <td>0.2341</td>\n",
       "      <td>0.1475</td>\n",
       "      <td>0.0845</td>\n",
       "      <td>0.3232</td>\n",
       "      <td>0.2387</td>\n",
       "      <td>0.0813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>s002</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.1249</td>\n",
       "      <td>0.2317</td>\n",
       "      <td>0.1068</td>\n",
       "      <td>0.0895</td>\n",
       "      <td>0.1676</td>\n",
       "      <td>0.0781</td>\n",
       "      <td>0.0903</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1312</td>\n",
       "      <td>0.1582</td>\n",
       "      <td>0.0270</td>\n",
       "      <td>0.0884</td>\n",
       "      <td>0.2517</td>\n",
       "      <td>0.1633</td>\n",
       "      <td>0.0903</td>\n",
       "      <td>0.2517</td>\n",
       "      <td>0.1614</td>\n",
       "      <td>0.0818</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  subject  sessionIndex  rep  H.period  DD.period.t  UD.period.t     H.t  \\\n",
       "0    s002             1    1    0.1491       0.3979       0.2488  0.1069   \n",
       "1    s002             1    2    0.1111       0.3451       0.2340  0.0694   \n",
       "2    s002             1    3    0.1328       0.2072       0.0744  0.0731   \n",
       "3    s002             1    4    0.1291       0.2515       0.1224  0.1059   \n",
       "4    s002             1    5    0.1249       0.2317       0.1068  0.0895   \n",
       "\n",
       "   DD.t.i  UD.t.i     H.i  ...     H.a  DD.a.n  UD.a.n     H.n  DD.n.l  \\\n",
       "0  0.1674  0.0605  0.1169  ...  0.1349  0.1484  0.0135  0.0932  0.3515   \n",
       "1  0.1283  0.0589  0.0908  ...  0.1412  0.2558  0.1146  0.1146  0.2642   \n",
       "2  0.1291  0.0560  0.0821  ...  0.1621  0.2332  0.0711  0.1172  0.2705   \n",
       "3  0.2495  0.1436  0.1040  ...  0.1457  0.1629  0.0172  0.0866  0.2341   \n",
       "4  0.1676  0.0781  0.0903  ...  0.1312  0.1582  0.0270  0.0884  0.2517   \n",
       "\n",
       "   UD.n.l     H.l  DD.l.Return  UD.l.Return  H.Return  \n",
       "0  0.2583  0.1338       0.3509       0.2171    0.0742  \n",
       "1  0.1496  0.0839       0.2756       0.1917    0.0747  \n",
       "2  0.1533  0.1085       0.2847       0.1762    0.0945  \n",
       "3  0.1475  0.0845       0.3232       0.2387    0.0813  \n",
       "4  0.1633  0.0903       0.2517       0.1614    0.0818  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['subject', 'sessionIndex', 'rep', 'H.period', 'DD.period.t',\n",
       "       'UD.period.t', 'H.t', 'DD.t.i', 'UD.t.i', 'H.i', 'DD.i.e', 'UD.i.e',\n",
       "       'H.e', 'DD.e.five', 'UD.e.five', 'H.five', 'DD.five.Shift.r',\n",
       "       'UD.five.Shift.r', 'H.Shift.r', 'DD.Shift.r.o', 'UD.Shift.r.o', 'H.o',\n",
       "       'DD.o.a', 'UD.o.a', 'H.a', 'DD.a.n', 'UD.a.n', 'H.n', 'DD.n.l',\n",
       "       'UD.n.l', 'H.l', 'DD.l.Return', 'UD.l.Return', 'H.Return'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20400, 34)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['s002', 's003', 's004', 's005', 's007', 's008', 's010', 's011',\n",
       "       's012', 's013', 's015', 's016', 's017', 's018', 's019', 's020',\n",
       "       's021', 's022', 's024', 's025', 's026', 's027', 's028', 's029',\n",
       "       's030', 's031', 's032', 's033', 's034', 's035', 's036', 's037',\n",
       "       's038', 's039', 's040', 's041', 's042', 's043', 's044', 's046',\n",
       "       's047', 's048', 's049', 's050', 's051', 's052', 's053', 's054',\n",
       "       's055', 's056', 's057'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subjects = data[\"subject\"].unique()\n",
    "subjects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach\n",
    "\n",
    "1. Out of 400 samples for each user, 200 used for training \n",
    "\n",
    "2. For testing rest 200 will be used along with 5 samples each from the rest 50 users for each user, so a total of 450 samples for testing\n",
    "\n",
    "3. compare the testing results, both the user's itself and the others for each user and see the difference (intuition: less the difference, more likely) (difference can be in terms of distance or error or anything of that sort)\n",
    "\n",
    "4. for loops are used, a model is made for each user\n",
    "\n",
    "## To decide\n",
    "\n",
    "1. which model to use (simple manhattan distance can give intuition to start, try SVM, then try NN)\n",
    "\n",
    "2. What metric to use for finding accuracy or misclassification "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. One Class SVM\n",
    "\n",
    "What if you only have data of one class and the goal is to test new data and found out whether it is alike or not like the training data? A method for this task, which gained much popularity the last two decades, is the One-Class Support Vector Machine. \n",
    "\n",
    "It basically separates all the data points from the origin (in feature space F) and maximizes the distance from this hyperplane to the origin. This results in a binary function which captures regions in the input space where the probability density of the data lives. Thus the function returns +1 in a “small” region (capturing the training data points) and −1 elsewhere.\n",
    "\n",
    "http://rvlasveld.github.io/blog/2013/07/12/introduction-to-one-class-support-vector-machines/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.svm import OneClassSVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Equal error rate (ERR)\n",
    "\n",
    "Equal error rate (EER) is a biometric security system algorithm used to predetermines the threshold values for its false acceptance rate and its false rejection rate. When the rates are equal, the common value is referred to as the equal error rate. The value indicates that the proportion of false acceptances is equal to the proportion of false rejections. The lower the equal error rate value, the higher the accuracy of the biometric system.\n",
    "\n",
    "FAR(FalseAcceptanceRate) = Numberoffalseacceptance / Numberofidentificationattempt\n",
    "\n",
    "FRR(FalseRejectionRate) = Numberoffalserejection / Numberofidentificationattempt\n",
    "\n",
    "ERR = (FAR + FRR) / 2\n",
    "\n",
    "ACC = 100 - ERR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateEER(user_scores, imposter_scores):\n",
    "    labels = [0]*len(user_scores) + [1]*len(imposter_scores)\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(labels, user_scores + imposter_scores)\n",
    "    frrates = 1 - tpr\n",
    "    farates = fpr\n",
    "    dists = frrates - farates\n",
    "    idx1 = np.argmin(dists[dists >= 0])\n",
    "    idx2 = np.argmax(dists[dists < 0])\n",
    "    x = [frrates[idx1], farates[idx1]]\n",
    "    y = [frrates[idx2], farates[idx2]]\n",
    "    a = ( x[0] - x[1] ) / ( y[1] - x[1] - y[0] + x[0] )\n",
    "    eer = x[0] + a * ( y[0] - x[0] )\n",
    "    acc = 1 - eer\n",
    "    return eer, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.175627732540059\n",
      "0.8243722674599411\n"
     ]
    }
   ],
   "source": [
    "# preparing training and testing data for each user\n",
    "eers = []\n",
    "accs = []\n",
    "for subj in subjects:\n",
    "    user_data = data.loc[data.subject == subj, 'H.period':'H.Return']\n",
    "    train_data = user_data[:200]\n",
    "    user_test_data = user_data[200:]\n",
    "    imposter_test_data = data.loc[data.subject != subj,:]\n",
    "    imposter_test_data = imposter_test_data.groupby('subject').head(5).loc[:, \"H.period\":\"H.Return\"]\n",
    "    test_data = user_test_data.append(imposter_test_data)\n",
    "    clf = OneClassSVM(kernel='linear',gamma=0.001, nu=0.95)\n",
    "    clf.fit(train_data)\n",
    "    u_scores = clf.decision_function(user_test_data)\n",
    "    i_scores = clf.decision_function(imposter_test_data)\n",
    "    u_scores = list(u_scores)\n",
    "    i_scores = list(i_scores)\n",
    "    fraud_pred = clf.predict(test_data)\n",
    "    eer, acc = evaluateEER(u_scores, i_scores)\n",
    "    eers.append(eer)\n",
    "    accs.append(acc)\n",
    "print(np.mean(eers))\n",
    "print(np.mean(accs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data.loc[data.subject == 's002', 'H.period':'H.Return']\n",
    "y = data.loc[data.subject == 's002', 'subject']\n",
    "for subj in subjects[1:10]:\n",
    "    x = x.append(data.loc[data.subject == subj, 'H.period':'H.Return'])\n",
    "    y = y.append(data.loc[data.subject == subj, 'subject'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4000, 1)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = pd.DataFrame(y)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "Y = y.apply(le.fit_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Karthika\\Anaconda2\\envs\\jupyter36\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:368: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(4000, 10)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc = preprocessing.OneHotEncoder()\n",
    "enc.fit(Y)\n",
    "onehotlabels = enc.transform(Y).toarray()\n",
    "onehotlabels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x, onehotlabels, test_size=0.3, random_state=0, stratify=onehotlabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2800, 31)\n",
      "(2800, 10)\n",
      "(1200, 31)\n",
      "(1200, 10)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 25)                800       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 25)                650       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                260       \n",
      "=================================================================\n",
      "Total params: 1,710\n",
      "Trainable params: 1,710\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation\n",
    "\n",
    "network = Sequential()\n",
    "network.add(Dense(25,input_dim=31,activation='relu'))\n",
    "network.add(Dense(25,activation='relu'))\n",
    "network.add(Dense(10, activation = 'softmax'))\n",
    "network.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2240 samples, validate on 560 samples\n",
      "Epoch 1/100\n",
      "2240/2240 [==============================] - 11s 5ms/step - loss: 0.0896 - acc: 0.1098 - val_loss: 0.0886 - val_acc: 0.1286\n",
      "Epoch 2/100\n",
      "2240/2240 [==============================] - 1s 422us/step - loss: 0.0870 - acc: 0.2549 - val_loss: 0.0843 - val_acc: 0.2946\n",
      "Epoch 3/100\n",
      "2240/2240 [==============================] - 1s 409us/step - loss: 0.0812 - acc: 0.3304 - val_loss: 0.0774 - val_acc: 0.3732\n",
      "Epoch 4/100\n",
      "2240/2240 [==============================] - 1s 426us/step - loss: 0.0736 - acc: 0.3973 - val_loss: 0.0702 - val_acc: 0.4036\n",
      "Epoch 5/100\n",
      "2240/2240 [==============================] - 1s 411us/step - loss: 0.0674 - acc: 0.4799 - val_loss: 0.0641 - val_acc: 0.6589\n",
      "Epoch 6/100\n",
      "2240/2240 [==============================] - 1s 435us/step - loss: 0.0616 - acc: 0.6179 - val_loss: 0.0594 - val_acc: 0.6250\n",
      "Epoch 7/100\n",
      "2240/2240 [==============================] - 1s 422us/step - loss: 0.0561 - acc: 0.6848 - val_loss: 0.0520 - val_acc: 0.7429\n",
      "Epoch 8/100\n",
      "2240/2240 [==============================] - 1s 437us/step - loss: 0.0507 - acc: 0.7308 - val_loss: 0.0466 - val_acc: 0.7571\n",
      "Epoch 9/100\n",
      "2240/2240 [==============================] - 1s 417us/step - loss: 0.0461 - acc: 0.7504 - val_loss: 0.0433 - val_acc: 0.7696\n",
      "Epoch 10/100\n",
      "2240/2240 [==============================] - 1s 439us/step - loss: 0.0426 - acc: 0.7643 - val_loss: 0.0398 - val_acc: 0.7857\n",
      "Epoch 11/100\n",
      "2240/2240 [==============================] - 1s 389us/step - loss: 0.0396 - acc: 0.7763 - val_loss: 0.0364 - val_acc: 0.8054\n",
      "Epoch 12/100\n",
      "2240/2240 [==============================] - 1s 423us/step - loss: 0.0372 - acc: 0.7871 - val_loss: 0.0352 - val_acc: 0.8125\n",
      "Epoch 13/100\n",
      "2240/2240 [==============================] - 1s 430us/step - loss: 0.0353 - acc: 0.7946 - val_loss: 0.0329 - val_acc: 0.8214\n",
      "Epoch 14/100\n",
      "2240/2240 [==============================] - 1s 408us/step - loss: 0.0336 - acc: 0.8067 - val_loss: 0.0318 - val_acc: 0.8232\n",
      "Epoch 15/100\n",
      "2240/2240 [==============================] - 1s 446us/step - loss: 0.0323 - acc: 0.8076 - val_loss: 0.0304 - val_acc: 0.8214\n",
      "Epoch 16/100\n",
      "2240/2240 [==============================] - 1s 402us/step - loss: 0.0309 - acc: 0.8174 - val_loss: 0.0292 - val_acc: 0.8321\n",
      "Epoch 17/100\n",
      "2240/2240 [==============================] - 1s 516us/step - loss: 0.0301 - acc: 0.8277 - val_loss: 0.0287 - val_acc: 0.8411\n",
      "Epoch 18/100\n",
      "2240/2240 [==============================] - 1s 453us/step - loss: 0.0289 - acc: 0.8313 - val_loss: 0.0272 - val_acc: 0.8446\n",
      "Epoch 19/100\n",
      "2240/2240 [==============================] - 1s 402us/step - loss: 0.0280 - acc: 0.8335 - val_loss: 0.0270 - val_acc: 0.8411\n",
      "Epoch 20/100\n",
      "2240/2240 [==============================] - 1s 409us/step - loss: 0.0272 - acc: 0.8366 - val_loss: 0.0260 - val_acc: 0.8589\n",
      "Epoch 21/100\n",
      "2240/2240 [==============================] - 1s 417us/step - loss: 0.0265 - acc: 0.8433 - val_loss: 0.0257 - val_acc: 0.8554\n",
      "Epoch 22/100\n",
      "2240/2240 [==============================] - 1s 405us/step - loss: 0.0259 - acc: 0.8509 - val_loss: 0.0256 - val_acc: 0.8625\n",
      "Epoch 23/100\n",
      "2240/2240 [==============================] - 1s 401us/step - loss: 0.0251 - acc: 0.8562 - val_loss: 0.0246 - val_acc: 0.8661\n",
      "Epoch 24/100\n",
      "2240/2240 [==============================] - 1s 414us/step - loss: 0.0246 - acc: 0.8522 - val_loss: 0.0244 - val_acc: 0.8554\n",
      "Epoch 25/100\n",
      "2240/2240 [==============================] - 1s 399us/step - loss: 0.0241 - acc: 0.8585 - val_loss: 0.0240 - val_acc: 0.8643\n",
      "Epoch 26/100\n",
      "2240/2240 [==============================] - 1s 408us/step - loss: 0.0236 - acc: 0.8603 - val_loss: 0.0235 - val_acc: 0.8607\n",
      "Epoch 27/100\n",
      "2240/2240 [==============================] - 1s 419us/step - loss: 0.0232 - acc: 0.8638 - val_loss: 0.0230 - val_acc: 0.8732\n",
      "Epoch 28/100\n",
      "2240/2240 [==============================] - 1s 392us/step - loss: 0.0228 - acc: 0.8634 - val_loss: 0.0230 - val_acc: 0.8732\n",
      "Epoch 29/100\n",
      "2240/2240 [==============================] - 1s 419us/step - loss: 0.0225 - acc: 0.8688 - val_loss: 0.0235 - val_acc: 0.8696\n",
      "Epoch 30/100\n",
      "2240/2240 [==============================] - 1s 411us/step - loss: 0.0221 - acc: 0.8652 - val_loss: 0.0229 - val_acc: 0.8661\n",
      "Epoch 31/100\n",
      "2240/2240 [==============================] - 1s 386us/step - loss: 0.0219 - acc: 0.8705 - val_loss: 0.0226 - val_acc: 0.8732\n",
      "Epoch 32/100\n",
      "2240/2240 [==============================] - 1s 411us/step - loss: 0.0213 - acc: 0.8759 - val_loss: 0.0223 - val_acc: 0.8839\n",
      "Epoch 33/100\n",
      "2240/2240 [==============================] - 1s 416us/step - loss: 0.0212 - acc: 0.8728 - val_loss: 0.0220 - val_acc: 0.8839\n",
      "Epoch 34/100\n",
      "2240/2240 [==============================] - 1s 396us/step - loss: 0.0208 - acc: 0.8777 - val_loss: 0.0218 - val_acc: 0.8804\n",
      "Epoch 35/100\n",
      "2240/2240 [==============================] - 1s 395us/step - loss: 0.0206 - acc: 0.8768 - val_loss: 0.0216 - val_acc: 0.8839\n",
      "Epoch 36/100\n",
      "2240/2240 [==============================] - 1s 404us/step - loss: 0.0203 - acc: 0.8799 - val_loss: 0.0210 - val_acc: 0.8804\n",
      "Epoch 37/100\n",
      "2240/2240 [==============================] - 1s 411us/step - loss: 0.0202 - acc: 0.8804 - val_loss: 0.0208 - val_acc: 0.8714\n",
      "Epoch 38/100\n",
      "2240/2240 [==============================] - 1s 413us/step - loss: 0.0198 - acc: 0.8821 - val_loss: 0.0207 - val_acc: 0.8786\n",
      "Epoch 39/100\n",
      "2240/2240 [==============================] - 1s 411us/step - loss: 0.0196 - acc: 0.8839 - val_loss: 0.0205 - val_acc: 0.8804\n",
      "Epoch 40/100\n",
      "2240/2240 [==============================] - 1s 408us/step - loss: 0.0195 - acc: 0.8835 - val_loss: 0.0204 - val_acc: 0.8857\n",
      "Epoch 41/100\n",
      "2240/2240 [==============================] - 1s 390us/step - loss: 0.0192 - acc: 0.8853 - val_loss: 0.0201 - val_acc: 0.8821\n",
      "Epoch 42/100\n",
      "2240/2240 [==============================] - 1s 405us/step - loss: 0.0190 - acc: 0.8879 - val_loss: 0.0204 - val_acc: 0.8875\n",
      "Epoch 43/100\n",
      "2240/2240 [==============================] - 1s 419us/step - loss: 0.0192 - acc: 0.8862 - val_loss: 0.0197 - val_acc: 0.8857\n",
      "Epoch 44/100\n",
      "2240/2240 [==============================] - 1s 409us/step - loss: 0.0189 - acc: 0.8893 - val_loss: 0.0200 - val_acc: 0.8804\n",
      "Epoch 45/100\n",
      "2240/2240 [==============================] - 1s 406us/step - loss: 0.0187 - acc: 0.8879 - val_loss: 0.0196 - val_acc: 0.8893\n",
      "Epoch 46/100\n",
      "2240/2240 [==============================] - 1s 390us/step - loss: 0.0184 - acc: 0.8897 - val_loss: 0.0204 - val_acc: 0.8786\n",
      "Epoch 47/100\n",
      "2240/2240 [==============================] - 1s 407us/step - loss: 0.0183 - acc: 0.8893 - val_loss: 0.0195 - val_acc: 0.8857\n",
      "Epoch 48/100\n",
      "2240/2240 [==============================] - 1s 399us/step - loss: 0.0181 - acc: 0.8951 - val_loss: 0.0190 - val_acc: 0.8911\n",
      "Epoch 49/100\n",
      "2240/2240 [==============================] - 1s 413us/step - loss: 0.0181 - acc: 0.8929 - val_loss: 0.0191 - val_acc: 0.8857\n",
      "Epoch 50/100\n",
      "2240/2240 [==============================] - 1s 406us/step - loss: 0.0178 - acc: 0.8906 - val_loss: 0.0195 - val_acc: 0.8821\n",
      "Epoch 51/100\n",
      "2240/2240 [==============================] - 1s 409us/step - loss: 0.0178 - acc: 0.8942 - val_loss: 0.0186 - val_acc: 0.8911\n",
      "Epoch 52/100\n",
      "2240/2240 [==============================] - 1s 399us/step - loss: 0.0175 - acc: 0.8933 - val_loss: 0.0196 - val_acc: 0.8839\n",
      "Epoch 53/100\n",
      "2240/2240 [==============================] - 1s 391us/step - loss: 0.0176 - acc: 0.8946 - val_loss: 0.0188 - val_acc: 0.8839\n",
      "Epoch 54/100\n",
      "2240/2240 [==============================] - 1s 401us/step - loss: 0.0174 - acc: 0.8978 - val_loss: 0.0184 - val_acc: 0.8875\n",
      "Epoch 55/100\n",
      "2240/2240 [==============================] - 1s 399us/step - loss: 0.0171 - acc: 0.8973 - val_loss: 0.0185 - val_acc: 0.8857\n",
      "Epoch 56/100\n",
      "2240/2240 [==============================] - 1s 390us/step - loss: 0.0171 - acc: 0.8982 - val_loss: 0.0186 - val_acc: 0.8857\n",
      "Epoch 57/100\n",
      "2240/2240 [==============================] - 1s 392us/step - loss: 0.0168 - acc: 0.9004 - val_loss: 0.0183 - val_acc: 0.8857\n",
      "Epoch 58/100\n",
      "2240/2240 [==============================] - 1s 393us/step - loss: 0.0167 - acc: 0.8996 - val_loss: 0.0180 - val_acc: 0.8946\n",
      "Epoch 59/100\n",
      "2240/2240 [==============================] - 1s 390us/step - loss: 0.0165 - acc: 0.8996 - val_loss: 0.0187 - val_acc: 0.8839\n",
      "Epoch 60/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2240/2240 [==============================] - 1s 415us/step - loss: 0.0166 - acc: 0.8996 - val_loss: 0.0178 - val_acc: 0.8893\n",
      "Epoch 61/100\n",
      "2240/2240 [==============================] - 1s 416us/step - loss: 0.0164 - acc: 0.9022 - val_loss: 0.0179 - val_acc: 0.8946\n",
      "Epoch 62/100\n",
      "2240/2240 [==============================] - 1s 423us/step - loss: 0.0162 - acc: 0.9058 - val_loss: 0.0178 - val_acc: 0.8929\n",
      "Epoch 63/100\n",
      "2240/2240 [==============================] - 1s 416us/step - loss: 0.0161 - acc: 0.9018 - val_loss: 0.0178 - val_acc: 0.8857\n",
      "Epoch 64/100\n",
      "2240/2240 [==============================] - 1s 429us/step - loss: 0.0160 - acc: 0.9040 - val_loss: 0.0181 - val_acc: 0.8875\n",
      "Epoch 65/100\n",
      "2240/2240 [==============================] - 1s 418us/step - loss: 0.0161 - acc: 0.9027 - val_loss: 0.0179 - val_acc: 0.8857\n",
      "Epoch 66/100\n",
      "2240/2240 [==============================] - 1s 421us/step - loss: 0.0161 - acc: 0.9045 - val_loss: 0.0178 - val_acc: 0.8893\n",
      "Epoch 67/100\n",
      "2240/2240 [==============================] - 1s 414us/step - loss: 0.0159 - acc: 0.9062 - val_loss: 0.0173 - val_acc: 0.8964\n",
      "Epoch 68/100\n",
      "2240/2240 [==============================] - 1s 432us/step - loss: 0.0159 - acc: 0.9049 - val_loss: 0.0175 - val_acc: 0.8875\n",
      "Epoch 69/100\n",
      "2240/2240 [==============================] - 1s 430us/step - loss: 0.0159 - acc: 0.9036 - val_loss: 0.0176 - val_acc: 0.8929\n",
      "Epoch 70/100\n",
      "2240/2240 [==============================] - 1s 384us/step - loss: 0.0155 - acc: 0.9054 - val_loss: 0.0177 - val_acc: 0.8964\n",
      "Epoch 71/100\n",
      "2240/2240 [==============================] - 1s 403us/step - loss: 0.0154 - acc: 0.9067 - val_loss: 0.0170 - val_acc: 0.8911\n",
      "Epoch 72/100\n",
      "2240/2240 [==============================] - 1s 414us/step - loss: 0.0156 - acc: 0.9062 - val_loss: 0.0168 - val_acc: 0.8964\n",
      "Epoch 73/100\n",
      "2240/2240 [==============================] - 1s 416us/step - loss: 0.0154 - acc: 0.9045 - val_loss: 0.0170 - val_acc: 0.8839\n",
      "Epoch 74/100\n",
      "2240/2240 [==============================] - 1s 431us/step - loss: 0.0154 - acc: 0.9054 - val_loss: 0.0171 - val_acc: 0.8875\n",
      "Epoch 75/100\n",
      "2240/2240 [==============================] - 1s 404us/step - loss: 0.0154 - acc: 0.9067 - val_loss: 0.0168 - val_acc: 0.8893\n",
      "Epoch 76/100\n",
      "2240/2240 [==============================] - 1s 407us/step - loss: 0.0151 - acc: 0.9076 - val_loss: 0.0170 - val_acc: 0.8911\n",
      "Epoch 77/100\n",
      "2240/2240 [==============================] - 1s 406us/step - loss: 0.0150 - acc: 0.9103 - val_loss: 0.0169 - val_acc: 0.8911\n",
      "Epoch 78/100\n",
      "2240/2240 [==============================] - 1s 400us/step - loss: 0.0149 - acc: 0.9121 - val_loss: 0.0170 - val_acc: 0.8893\n",
      "Epoch 79/100\n",
      "2240/2240 [==============================] - 1s 408us/step - loss: 0.0149 - acc: 0.9080 - val_loss: 0.0167 - val_acc: 0.8964\n",
      "Epoch 80/100\n",
      "2240/2240 [==============================] - 1s 413us/step - loss: 0.0150 - acc: 0.9094 - val_loss: 0.0164 - val_acc: 0.9000\n",
      "Epoch 81/100\n",
      "2240/2240 [==============================] - 1s 421us/step - loss: 0.0148 - acc: 0.9085 - val_loss: 0.0164 - val_acc: 0.9018\n",
      "Epoch 82/100\n",
      "2240/2240 [==============================] - 1s 396us/step - loss: 0.0147 - acc: 0.9098 - val_loss: 0.0165 - val_acc: 0.8893\n",
      "Epoch 83/100\n",
      "2240/2240 [==============================] - 1s 411us/step - loss: 0.0147 - acc: 0.9116 - val_loss: 0.0162 - val_acc: 0.8982\n",
      "Epoch 84/100\n",
      "2240/2240 [==============================] - 1s 403us/step - loss: 0.0147 - acc: 0.9107 - val_loss: 0.0164 - val_acc: 0.8982\n",
      "Epoch 85/100\n",
      "2240/2240 [==============================] - 1s 408us/step - loss: 0.0148 - acc: 0.9085 - val_loss: 0.0163 - val_acc: 0.8964\n",
      "Epoch 86/100\n",
      "2240/2240 [==============================] - 1s 420us/step - loss: 0.0147 - acc: 0.9143 - val_loss: 0.0165 - val_acc: 0.9000\n",
      "Epoch 87/100\n",
      "2240/2240 [==============================] - 1s 405us/step - loss: 0.0146 - acc: 0.9129 - val_loss: 0.0164 - val_acc: 0.8982\n",
      "Epoch 88/100\n",
      "2240/2240 [==============================] - 1s 408us/step - loss: 0.0143 - acc: 0.9121 - val_loss: 0.0160 - val_acc: 0.9000\n",
      "Epoch 89/100\n",
      "2240/2240 [==============================] - 1s 375us/step - loss: 0.0144 - acc: 0.9125 - val_loss: 0.0165 - val_acc: 0.9018\n",
      "Epoch 90/100\n",
      "2240/2240 [==============================] - 1s 415us/step - loss: 0.0144 - acc: 0.9152 - val_loss: 0.0160 - val_acc: 0.9000\n",
      "Epoch 91/100\n",
      "2240/2240 [==============================] - 1s 418us/step - loss: 0.0143 - acc: 0.9147 - val_loss: 0.0163 - val_acc: 0.8982\n",
      "Epoch 92/100\n",
      "2240/2240 [==============================] - 1s 415us/step - loss: 0.0142 - acc: 0.9156 - val_loss: 0.0168 - val_acc: 0.8964\n",
      "Epoch 93/100\n",
      "2240/2240 [==============================] - 1s 409us/step - loss: 0.0141 - acc: 0.9161 - val_loss: 0.0160 - val_acc: 0.8964\n",
      "Epoch 94/100\n",
      "2240/2240 [==============================] - 1s 402us/step - loss: 0.0140 - acc: 0.9174 - val_loss: 0.0161 - val_acc: 0.8982\n",
      "Epoch 95/100\n",
      "2240/2240 [==============================] - 1s 467us/step - loss: 0.0142 - acc: 0.9121 - val_loss: 0.0158 - val_acc: 0.9054\n",
      "Epoch 96/100\n",
      "2240/2240 [==============================] - 1s 410us/step - loss: 0.0141 - acc: 0.9152 - val_loss: 0.0163 - val_acc: 0.8982\n",
      "Epoch 97/100\n",
      "2240/2240 [==============================] - 1s 399us/step - loss: 0.0141 - acc: 0.9156 - val_loss: 0.0158 - val_acc: 0.8964\n",
      "Epoch 98/100\n",
      "2240/2240 [==============================] - 1s 418us/step - loss: 0.0139 - acc: 0.9156 - val_loss: 0.0159 - val_acc: 0.9000\n",
      "Epoch 99/100\n",
      "2240/2240 [==============================] - 1s 414us/step - loss: 0.0138 - acc: 0.9179 - val_loss: 0.0161 - val_acc: 0.9018\n",
      "Epoch 100/100\n",
      "2240/2240 [==============================] - 1s 413us/step - loss: 0.0139 - acc: 0.9174 - val_loss: 0.0160 - val_acc: 0.9018\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x18f4bf872b0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network.compile(loss='mean_squared_error',optimizer='adam', metrics = ['accuracy'])\n",
    "network.fit(X_train,y_train,epochs=100,batch_size=20,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.8783333333333333\n"
     ]
    }
   ],
   "source": [
    "test_scores = network.evaluate(X_test, y_test, verbose = 0)\n",
    "print('Test accuracy:', test_scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = network.predict(X_test[3:4])\n",
    "y_pred.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[3:4].argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
